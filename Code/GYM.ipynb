{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install mlagents==0.28.0\n",
    "# !python -m pip install gym\n",
    "# !cd \"/Users/aditya/Documents/GitHub/game_creation_research/ml-agents/gym-unity\" && pip3 install -e .\n",
    "\n",
    "import mlagents\n",
    "import numpy as np\n",
    "import json\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from collections import namedtuple, defaultdict\n",
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "from gym_unity.envs import UnityToGymWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "Vector2 = namedtuple('Vector2', 'x y')\n",
    "\n",
    "class Obs():\n",
    "    def __init__(self, raw_obs):\n",
    "        \"\"\"\n",
    "        Converts Unity Agent outputted Vector Observation to \n",
    "        named format\n",
    "        \"\"\"\n",
    "        self.raw_obs = raw_obs\n",
    "        self.objectOrder = [\"corner\", \"bucket\", \"triangle\", \"gear\", \"crate\"]\n",
    "        self.objPos = {}\n",
    "        self.objPos[self.objectOrder[0]] = Vector2(raw_obs[0], raw_obs[1])\n",
    "        self.objPos[self.objectOrder[1]] = Vector2(raw_obs[2], raw_obs[3])\n",
    "        self.objPos[self.objectOrder[2]] = Vector2(raw_obs[4], raw_obs[5])\n",
    "        self.objPos[self.objectOrder[3]] = Vector2(raw_obs[6], raw_obs[7])\n",
    "        self.objPos[self.objectOrder[4]] = Vector2(raw_obs[8], raw_obs[9])\n",
    "        self.ballPos = Vector2(raw_obs[10], raw_obs[11])\n",
    "        self.ballVel = Vector2(raw_obs[12], raw_obs[13])\n",
    "        self.reset = bool(raw_obs[14])\n",
    "\n",
    "    def show(self) -> None:\n",
    "        \"\"\"\n",
    "        Pretty Print Observation\n",
    "        \"\"\"\n",
    "        for each_obj in self.objPos:\n",
    "            print(f\"{each_obj}: {self.objPos[each_obj]}\")\n",
    "        print(f\"Ball Position: {self.ballPos}\")\n",
    "        print(f\"Ball Velocity: {self.ballVel}\")\n",
    "        print(f\"In Reset?: {self.reset}\")\n",
    "    \n",
    "    def toArray(self):\n",
    "        return self.raw_obs\n",
    "\n",
    "class PlaceAndShootGym(UnityToGymWrapper):\n",
    "    def __init__(self, gym_env, reward_fn):\n",
    "        self.gym_env = gym_env\n",
    "        self.reward_fn = reward_fn\n",
    "        # unsure if this is always true\n",
    "        self.velTresh = 0.001\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Step is defined as doing something ball has stopped\n",
    "        \"\"\"\n",
    "        obsVec = []\n",
    "        # first step\n",
    "        raw_obs, _reward, _done, info = self.gym_env.step(action)\n",
    "        obsVec.append(Obs(raw_obs))\n",
    "        # continued steps\n",
    "        while (any([abs(f)>self.velTresh for f in obsVec[-1].ballVel])):\n",
    "            raw_obs, _reward, done, info = self.gym_env.step(action)\n",
    "            obsVec.append(Obs(raw_obs))\n",
    "        reward = self.getRewards(obsVec)\n",
    "        return (obsVec[-1].toArray(), reward, done, info)\n",
    "    \n",
    "    def getRewards(self, obsVec: List[Obs]) -> float:\n",
    "        return float(self.reward_fn(obsVec))\n",
    "\n",
    "    def close(self):\n",
    "        self.gym_env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def endsInBucket(obsVec: List[Obs]) -> bool:\n",
    "    \"\"\"\n",
    "    Custom Reward Fn:\n",
    "    Is that ball in bucket at the end or no?\n",
    "    \"\"\"\n",
    "    MIN_X_DELTA = -0.1927506923675537\n",
    "    MAX_X_DELTA = 0.2523689270019531\n",
    "    MIN_Y_DELTA = -0.24334418773651123\n",
    "    MAX_Y_DELTA = 0.6142134666442871\n",
    "\n",
    "    ball_x, ball_y = obsVec[-1].ballPos\n",
    "    bucket_x, bucket_y = obsVec[-1].objPos[\"bucket\"]\n",
    "    x_delta = ball_x - bucket_x\n",
    "    y_delta = ball_y - bucket_y\n",
    "\n",
    "    return (MAX_X_DELTA>=x_delta>=MIN_X_DELTA) and (MAX_Y_DELTA>=y_delta>=MIN_Y_DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.\n",
      "[INFO] Connected to Unity environment with package version 2.2.1-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: PlaceAndShoot?team=0\n",
      "[WARNING] The environment contains multiple observations. You must define allow_multiple_obs=True to receive them all. Otherwise, only the first visual observation (or vector observation ifthere are no visual observations) will be provided in the observation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/introml_conda/lib/python3.8/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "SERVER_BUILD = \"../Builds/MLAgent_View_21April22_server.app\"\n",
    "GRAPHICAL_BUILD = \"../Builds/MLAgent_View_21April22.app\"\n",
    "GYM_BUILD = \"../Builds/Gym_View_22April22.app\"\n",
    "\n",
    "# channel = EngineConfigurationChannel()\n",
    "# channel.set_configuration_parameters(time_scale = 1.0, quality_level=5)\n",
    "# unity_env = UnityEnvironment(file_name=GYM_BUILD, seed=1, side_channels=[channel], worker_id=1)\n",
    "\n",
    "unity_env = UnityEnvironment()\n",
    "\n",
    "# Start interacting with the environment.\n",
    "unity_env.reset()\n",
    "gym_env = UnityToGymWrapper(unity_env, allow_multiple_obs=False)\n",
    "env = PlaceAndShootGym(gym_env, endsInBucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.3400002e+00, -2.6500001e+00,  5.3400002e+00,  1.8500000e+00,\n",
       "         5.3400002e+00, -1.2500000e+00,  5.3400002e+00,  2.3999999e-01,\n",
       "         5.3400002e+00,  3.2600000e+00,  2.6835985e+00, -4.6035752e+00,\n",
       "        -9.7295688e-04,  0.0000000e+00,  0.0000000e+00], dtype=float32),\n",
       " 0.0,\n",
       " False,\n",
       " {'step': <mlagents_envs.base_env.DecisionSteps at 0x7fc8ebcf4280>})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = [-1.4, -1.5, 0, 0, 0, 0]\n",
    "env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9ca164c7b3bd0bb50cde96947fba4327d4d875f8b3488ae3586fafde6fb5019"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('introml_conda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
