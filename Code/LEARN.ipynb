{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "usage: mlagents-learn [-h] [--env ENV_PATH] [--resume] [--deterministic]\n",
    "                      [--force] [--run-id RUN_ID] [--initialize-from RUN_ID]\n",
    "                      [--seed SEED] [--inference] [--base-port BASE_PORT]\n",
    "                      [--num-envs NUM_ENVS] [--num-areas NUM_AREAS] [--debug]\n",
    "                      [--env-args ...]\n",
    "                      [--max-lifetime-restarts MAX_LIFETIME_RESTARTS]\n",
    "                      [--restarts-rate-limit-n RESTARTS_RATE_LIMIT_N]\n",
    "                      [--restarts-rate-limit-period-s RESTARTS_RATE_LIMIT_PERIOD_S]\n",
    "                      [--torch] [--tensorflow] [--results-dir RESULTS_DIR]\n",
    "                      [--width WIDTH] [--height HEIGHT]\n",
    "                      [--quality-level QUALITY_LEVEL]\n",
    "                      [--time-scale TIME_SCALE]\n",
    "                      [--target-frame-rate TARGET_FRAME_RATE]\n",
    "                      [--capture-frame-rate CAPTURE_FRAME_RATE]\n",
    "                      [--no-graphics] [--torch-device DEVICE]\n",
    "                      [trainer_config_path]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            ┐  ╖\n",
      "        ╓╖╬│╡  ││╬╖╖\n",
      "    ╓╖╬│││││┘  ╬│││││╬╖\n",
      " ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗\n",
      " ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣\n",
      " ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣\n",
      " ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣\n",
      " ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜\n",
      " ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣\n",
      " ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣\n",
      "   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣\n",
      "      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜\n",
      "          ╙╬╬╬╣╣╣╜\n",
      "             ╙\n",
      "        \n",
      " Version information:\n",
      "  ml-agents: 0.28.0,\n",
      "  ml-agents-envs: 0.28.0,\n",
      "  Communicator API: 1.5.0,\n",
      "  PyTorch: 1.8.1\n",
      "[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.\n",
      "[INFO] Connected to Unity environment with package version 2.2.1-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: PlaceAndShoot?team=0\n",
      "[INFO] Hyperparameters for behavior name PlaceAndShoot: \n",
      "\ttrainer_type:\tppo\n",
      "\thyperparameters:\t\n",
      "\t  batch_size:\t10\n",
      "\t  buffer_size:\t100\n",
      "\t  learning_rate:\t0.0003\n",
      "\t  beta:\t0.0005\n",
      "\t  epsilon:\t0.2\n",
      "\t  lambd:\t0.99\n",
      "\t  num_epoch:\t3\n",
      "\t  learning_rate_schedule:\tlinear\n",
      "\t  beta_schedule:\tconstant\n",
      "\t  epsilon_schedule:\tlinear\n",
      "\tnetwork_settings:\t\n",
      "\t  normalize:\tFalse\n",
      "\t  hidden_units:\t128\n",
      "\t  num_layers:\t3\n",
      "\t  vis_encode_type:\tsimple\n",
      "\t  memory:\tNone\n",
      "\t  goal_conditioning_type:\thyper\n",
      "\t  deterministic:\tFalse\n",
      "\treward_signals:\t\n",
      "\t  extrinsic:\t\n",
      "\t    gamma:\t0.99\n",
      "\t    strength:\t1.0\n",
      "\t    network_settings:\t\n",
      "\t      normalize:\tFalse\n",
      "\t      hidden_units:\t128\n",
      "\t      num_layers:\t2\n",
      "\t      vis_encode_type:\tsimple\n",
      "\t      memory:\tNone\n",
      "\t      goal_conditioning_type:\thyper\n",
      "\t      deterministic:\tFalse\n",
      "\tinit_path:\tNone\n",
      "\tkeep_checkpoints:\t5\n",
      "\tcheckpoint_interval:\t500000\n",
      "\tmax_steps:\t1000000\n",
      "\ttime_horizon:\t64\n",
      "\tsummary_freq:\t10000\n",
      "\tthreaded:\tFalse\n",
      "\tself_play:\tNone\n",
      "\tbehavioral_cloning:\tNone\n",
      "[INFO] Resuming from results/LearnToBucket/PlaceAndShoot.\n",
      "[INFO] Resuming training from step 69815.\n",
      "[WARNING] Restarting worker[0] after 'Communicator has exited.'\n",
      "[INFO] Listening on port 5004. Start training by pressing the Play button in the Unity Editor.\n",
      "[INFO] Exported results/LearnToBucket/PlaceAndShoot/PlaceAndShoot-69864.onnx\n",
      "[INFO] Copied results/LearnToBucket/PlaceAndShoot/PlaceAndShoot-69864.onnx to results/LearnToBucket/PlaceAndShoot.onnx.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/introml_conda/bin/mlagents-learn\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/anaconda3/envs/introml_conda/lib/python3.8/site-packages/mlagents/trainers/learn.py\", line 260, in main\n",
      "    run_cli(parse_command_line())\n",
      "  File \"/opt/anaconda3/envs/introml_conda/lib/python3.8/site-packages/mlagents/trainers/learn.py\", line 256, in run_cli\n",
      "    run_training(run_seed, options, num_areas)\n",
      "  File \"/opt/anaconda3/envs/introml_conda/lib/python3.8/site-packages/mlagents/trainers/learn.py\", line 132, in run_training\n",
      "    tc.start_learning(env_manager)\n",
      "  File \"/opt/anaconda3/envs/introml_conda/lib/python3.8/site-packages/mlagents_envs/timers.py\", line 305, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/introml_conda/lib/python3.8/site-packages/mlagents/trainers/trainer_controller.py\", line 176, in start_learning\n",
      "    n_steps = self.advance(env_manager)\n",
      "  File \"/opt/anaconda3/envs/introml_conda/lib/python3.8/site-packages/mlagents_envs/timers.py\", line 305, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/introml_conda/lib/python3.8/site-packages/mlagents/trainers/trainer_controller.py\", line 234, in advance\n",
      "    new_step_infos = env_manager.get_steps()\n",
      "  File \"/opt/anaconda3/envs/introml_conda/lib/python3.8/site-packages/mlagents/trainers/env_manager.py\", line 124, in get_steps\n",
      "    new_step_infos = self._step()\n",
      "  File \"/opt/anaconda3/envs/introml_conda/lib/python3.8/site-packages/mlagents/trainers/subprocess_env_manager.py\", line 420, in _step\n",
      "    self._restart_failed_workers(step)\n",
      "  File \"/opt/anaconda3/envs/introml_conda/lib/python3.8/site-packages/mlagents/trainers/subprocess_env_manager.py\", line 328, in _restart_failed_workers\n",
      "    self.reset(self.env_parameters)\n",
      "  File \"/opt/anaconda3/envs/introml_conda/lib/python3.8/site-packages/mlagents/trainers/env_manager.py\", line 68, in reset\n",
      "    self.first_step_infos = self._reset_env(config)\n",
      "  File \"/opt/anaconda3/envs/introml_conda/lib/python3.8/site-packages/mlagents/trainers/subprocess_env_manager.py\", line 446, in _reset_env\n",
      "    ew.previous_step = EnvironmentStep(ew.recv().payload, ew.worker_id, {}, {})\n",
      "  File \"/opt/anaconda3/envs/introml_conda/lib/python3.8/site-packages/mlagents/trainers/subprocess_env_manager.py\", line 101, in recv\n",
      "    raise env_exception\n",
      "mlagents_envs.exception.UnityTimeOutException: The Unity environment took too long to respond. Make sure that :\n",
      "\t The environment does not need user interaction to launch\n",
      "\t The Agents' Behavior Parameters > Behavior Type is set to \"Default\"\n",
      "\t The environment and the Python interface have compatible versions.\n",
      "\t If you're running on a headless server without graphics support, turn off display by either passing --no-graphics option or build your Unity executable as server build.\n"
     ]
    }
   ],
   "source": [
    "!mlagents-learn \"/Users/aditya/Documents/GitHub/game_creation_research/Object Physics Sandbox/Code/configs/train.yaml\" --run-id LearnToBucket --num-envs=1 --resume --time-scale 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.8.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir \"/Users/aditya/Documents/GitHub/game_creation_research/Object Physics Sandbox/Code/results\" --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9ca164c7b3bd0bb50cde96947fba4327d4d875f8b3488ae3586fafde6fb5019"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('introml_conda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
